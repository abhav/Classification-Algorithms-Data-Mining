{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import preprocessing \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertToLabel(df,pos):\n",
    "    label_encoder = preprocessing.LabelEncoder() \n",
    "    df[pos]= label_encoder.fit_transform(df[pos]) \n",
    "    return df\n",
    "\n",
    "def chunks(df, n):\n",
    "    for i in range(0, len(df), n):\n",
    "        yield df[i:i + n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:569 Y Shape: 31\n"
     ]
    }
   ],
   "source": [
    "X_1 = pd.read_csv(\"project3_dataset1.txt\",header=None, delimiter=\"\\t\")\n",
    "XShape, YShape = X_1.shape\n",
    "print('X Shape:' + str(XShape) + ' Y Shape: '+ str(YShape))\n",
    "Y_1 = X_1[YShape-1]\n",
    "X_1 = X_1.iloc[:, :YShape-1]\n",
    "X_1 = X_1.to_numpy()\n",
    "Y_1 = Y_1.to_numpy()\n",
    "X_1 = sklearn.preprocessing.normalize(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:462 Y Shape: 10\n"
     ]
    }
   ],
   "source": [
    "X_2 = pd.read_csv(\"project3_dataset2.txt\",header=None, delimiter=\"\\t\")\n",
    "XShape, YShape = X_2.shape\n",
    "print('X Shape:' + str(XShape) + ' Y Shape: '+ str(YShape))\n",
    "\n",
    "Y_2 = X_2[YShape-1]\n",
    "X_2 = ConvertToLabel(X_2,4)\n",
    "X_2 = X_2.iloc[:, :YShape-1]\n",
    "X_2 = X_2.to_numpy()\n",
    "Y_2 = Y_2.to_numpy()\n",
    "X_2 = sklearn.preprocessing.normalize(X_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_1, Y_1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8245614035087719\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_2, Y_2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6129032258064516\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occ(value, index, lt):\n",
    "    counter = 0\n",
    "    for row in lt:\n",
    "        if row[index] == value:\n",
    "            counter+=1\n",
    "    return counter\n",
    "\n",
    "def findMean(train_x):\n",
    "    return np.mean(train_x, axis=0)\n",
    "\n",
    "def findStdDev(train_x):\n",
    "    return np.std(train_x, axis=0)\n",
    "\n",
    "def gaussian(v,mean,stdDev,index):\n",
    "    return (1/(2 * 3.14 * (stdDev[index]**2))**0.5) * math.exp(-1 * ((v - mean[index])**2)/(2*(stdDev[index]**2)))\n",
    "\n",
    "def naiveBayes(train_x,train_y,test_x):\n",
    "    list_yes,list_no = [],[]\n",
    "    dict_yes,dict_no = {},{}\n",
    "    output = []\n",
    "    for i,items in enumerate(train_y):\n",
    "        if train_y[i] == 0.0:\n",
    "            list_no.append(train_x[i])\n",
    "        else:\n",
    "            list_yes.append(train_x[i])\n",
    "    mean1, stdDev1 = findMean(list_yes), findStdDev(list_yes)\n",
    "    mean2, stdDev2 = findMean(list_no), findStdDev(list_no)\n",
    "    for items in list_yes:\n",
    "        for index,item in enumerate(items):\n",
    "            if (index,item) not in dict_yes:\n",
    "                dict_yes[(index, item)] = gaussian(item, mean1, stdDev1, index)\n",
    "                \n",
    "    for items in list_no:\n",
    "        for index,item in enumerate(items):\n",
    "            if (index,item) not in dict_no:\n",
    "                dict_yes[(index, item)] = gaussian(item, mean2, stdDev2, index)\n",
    "\n",
    "    for item in test_x:\n",
    "        product_yes,product_no = 1.0, 1.0\n",
    "        for index, i in enumerate(item):\n",
    "            product_yes = product_yes * gaussian(i, mean1, stdDev1, index)\n",
    "            product_no = product_no * gaussian(i, mean2, stdDev2, index)\n",
    "      \n",
    "        product_yes = (product_yes) * (len(list_yes)/len(train_y))\n",
    "        product_no = (product_no) * (len(list_no)/len(train_y))\n",
    "\n",
    "        if product_yes >= product_no:\n",
    "            output.append(1.0)\n",
    "        else:\n",
    "            output.append(0.0)    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPredictedClass(predicted_labels,test_y):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "    for i in range(len(predicted_labels)):\n",
    "        if predicted_labels[i] == 1 and test_y[i] == 1:\n",
    "            tp+=1    \n",
    "        if predicted_labels[i] == 0 and test_y[i] == 0:\n",
    "            tn+=1\n",
    "        if predicted_labels[i] == 1 and test_y[i] == 0:\n",
    "            fp+=1\n",
    "        if predicted_labels[i] == 0 and test_y[i] == 1:\n",
    "            fn+=1\n",
    "    try:\n",
    "        accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "    except:\n",
    "        accuracy = 0.0\n",
    "    try:\n",
    "        precision = tp / (tp + fp)\n",
    "    except:\n",
    "        precision = 0.0\n",
    "    try:\n",
    "        recall = tp / (tp + fn)\n",
    "    except:\n",
    "        recall = 0.0\n",
    "    try:\n",
    "        fscore = 2 * (precision * recall)/(precision + recall)\n",
    "    except:\n",
    "        fscore = 0.0\n",
    "    return accuracy,precision,recall,fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataProcessing(X,Y):\n",
    "    data = np.column_stack((X, Y))\n",
    "    np.random.shuffle(data)\n",
    "    RowCount = math.ceil(len(X)/10)\n",
    "    output = list(chunks(data,RowCount))\n",
    "    print('Output Count:'+str(len(output))+' Output X Shape:'+str(len(output[0]))+' Output Y Shape:'+str(len(output[0][0])))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnNaiveBayes(output):\n",
    "    totalAccuracy, totalPrecision, totalRecall, totalFscore = [],[],[],[]\n",
    "    for i in range(len(output)):\n",
    "        test_x,test_y,train_x, train_y = [], [], [], []\n",
    "        train_x = [row for j,lt in enumerate(output) if j!=i for row in lt]\n",
    "        test_x = output[i]\n",
    "        for arr in test_x:\n",
    "            test_y.append(arr[-1])\n",
    "        for arr in train_x:\n",
    "            train_y.append(arr[-1])\n",
    "        train_x = np.delete(train_x, np.s_[-1:], axis=1)\n",
    "        test_x = np.delete(test_x, np.s_[-1:], axis=1)\n",
    "        \n",
    "        predicted_labels = naiveBayes(train_x,train_y,test_x)\n",
    "        accuracy, precision, recall, fscore = findPredictedClass(predicted_labels,test_y)\n",
    "        totalAccuracy.append(accuracy)\n",
    "        totalPrecision.append(precision)\n",
    "        totalRecall.append(recall)\n",
    "        totalFscore.append(fscore)\n",
    "\n",
    "    avgAccuracy  = np.mean(totalAccuracy)\n",
    "    avgPrecision = np.mean(totalPrecision)\n",
    "    avgRecall    = np.mean(totalRecall)\n",
    "    avgFscore    = np.mean(totalFscore)    \n",
    "    print('Avgerage Accuracy :'+ str(avgAccuracy))\n",
    "    print('Avgerage Precision :'+ str(avgPrecision))\n",
    "    print('Avgerage Recall :'+ str(avgRecall))\n",
    "    print('Avgerage Fscore :'+ str(avgFscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Count:10 Output X Shape:57 Output Y Shape:31\n",
      "Avgerage Accuracy :0.8118421052631579\n",
      "Avgerage Precision :0.6921608021910647\n",
      "Avgerage Recall :0.9101193968756898\n",
      "Avgerage Fscore :0.7820636944573826\n"
     ]
    }
   ],
   "source": [
    "output = dataProcessing(X_1, Y_1)\n",
    "knnNaiveBayes(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Count:10 Output X Shape:47 Output Y Shape:10\n",
      "Avgerage Accuracy :0.6921985815602837\n",
      "Avgerage Precision :0.567946571047594\n",
      "Avgerage Recall :0.5414020344980097\n",
      "Avgerage Fscore :0.5386643540272573\n"
     ]
    }
   ],
   "source": [
    "output_2 = dataProcessing(X_2, Y_2)\n",
    "knnNaiveBayes(output_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:80 Y Shape: 5\n"
     ]
    }
   ],
   "source": [
    "TrainData = pd.read_csv(\"project3_dataset3_train.txt\",header=None, delimiter=\"\\t\")\n",
    "XShape, YShape = TrainData.shape\n",
    "print('X Shape:' + str(XShape) + ' Y Shape: '+ str(YShape))\n",
    "TrainData_Y = TrainData[YShape-1]\n",
    "TrainData_X = TrainData.iloc[:, :YShape-1]\n",
    "TrainData_X = TrainData_X.to_numpy()\n",
    "TrainData_Y = TrainData_Y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:20 Y Shape: 5\n"
     ]
    }
   ],
   "source": [
    "TestData = pd.read_csv(\"project3_dataset3_test.txt\",header=None, delimiter=\"\\t\")\n",
    "XShape, YShape = TestData.shape\n",
    "print('X Shape:' + str(XShape) + ' Y Shape: '+ str(YShape))\n",
    "TestData_Y = TestData[YShape-1]\n",
    "TestData_X = TestData.iloc[:, :YShape-1]\n",
    "TestData_X = TestData_X.to_numpy()\n",
    "TestData_Y = TestData_Y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy :0.95\n",
      " Precision :0.9090909090909091\n",
      " Recall :1.0\n",
      " Fscore :0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = naiveBayes(TrainData_X, TrainData_Y, TestData_X)\n",
    "accuracy, precision, recall, fscore = findPredictedClass(predicted_labels,TestData_Y)\n",
    "print(' Accuracy :'+ str(accuracy))\n",
    "print(' Precision :'+ str(precision))\n",
    "print(' Recall :'+ str(recall))\n",
    "print(' Fscore :'+ str(fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data4 = pd.read_csv(\"project3_dataset4.txt\",header=None, delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,4):\n",
    "    Data4 = ConvertToLabel(Data4,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:14 Y Shape: 5\n"
     ]
    }
   ],
   "source": [
    "XShape, YShape = Data4.shape\n",
    "print('X Shape:' + str(XShape) + ' Y Shape: '+ str(YShape))\n",
    "Data4_Y = Data4[YShape-1]\n",
    "Data4_X = Data4.iloc[:, :YShape-1]\n",
    "Data4_X = Data4_X.to_numpy()\n",
    "Data4_Y = Data4_Y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Data4_X, Data4_Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy :0.8\n",
      " Precision :1.0\n",
      " Recall :0.5\n",
      " Fscore :0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = naiveBayes(X_train, y_train, X_test)\n",
    "accuracy, precision, recall, fscore = findPredictedClass(predicted_labels,y_test)\n",
    "print(' Accuracy :'+ str(accuracy))\n",
    "print(' Precision :'+ str(precision))\n",
    "print(' Recall :'+ str(recall))\n",
    "print(' Fscore :'+ str(fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As Requested for Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data4 = pd.read_csv(\"project3_dataset4.txt\",header=None, delimiter=\"\\t\")\n",
    "Data4 = Data4.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(dataset,testdata):\n",
    "\n",
    "    def getindex(dataset):\n",
    "        index = []\n",
    "        for i in range(dataset.shape[1]):\n",
    "            try:\n",
    "                float(dataset[0,i])\n",
    "            except ValueError:\n",
    "                index.append(i)\n",
    "        return index\n",
    "    \n",
    "    traindata = dataset\n",
    "    index = getindex(dataset)\n",
    "\n",
    "    labels = list(dataset[:,-1])\n",
    "\n",
    "    prior_0 = labels.count(0)/len(labels)\n",
    "    prior_1 = labels.count(1)/len(labels)\n",
    "\n",
    "    denominator = 1\n",
    "    for i in range(len(testdata)):\n",
    "        val = list(dataset[:,i])\n",
    "        num = val.count(testdata[i])\n",
    "        den = num/len(dataset)\n",
    "        denominator = denominator*den\n",
    "\n",
    "    post_0 = 1\n",
    "    post_1 = 1\n",
    "    for i in range(len(index)):\n",
    "        train_data = traindata[:,index[i]]\n",
    "        label_train = traindata[:, -1]\n",
    "        dict = {}\n",
    "        for j in range(len(label_train)):\n",
    "            if label_train[j] not in dict:\n",
    "                dict[label_train[j]] = []\n",
    "            dict[label_train[j]].append(train_data[j])\n",
    "        posterior_0 = dict[0].count(testdata[i])/len(dict[0])\n",
    "        posterior_1 = dict[1].count(testdata[i]) / len(dict[1])\n",
    "        post_0 = post_0 * posterior_0\n",
    "        post_1 = post_1 * posterior_1\n",
    "\n",
    "    prob_list = []\n",
    "    prob_0 = (post_0*prior_0)/denominator\n",
    "    prob_1 = (post_1*prior_1)/denominator\n",
    "    prob_list.append(prob_0)\n",
    "    prob_list.append(prob_1)\n",
    "    val = prob_list.index(max(prob_list))\n",
    "    print(post_0)\n",
    "    print(post_1)\n",
    "    print(prior_0)\n",
    "    print(prior_1)\n",
    "    #print(post_0*prior_0)\n",
    "    #print(post_1*prior_1)\n",
    "    print(\"probability for class 0 : \", prob_0/(prob_0+prob_1))\n",
    "    print(\"probability for class 1 : \", prob_1/(prob_0+prob_1))\n",
    "    print(\"The input will get classified to class : \", val)\n",
    "\n",
    "    return prob_0,prob_1,val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038400000000000004\n",
      "0.016460905349794237\n",
      "0.35714285714285715\n",
      "0.6428571428571429\n",
      "probability for class 0 :  0.5644599303135889\n",
      "probability for class 1 :  0.4355400696864111\n",
      "The input will get classified to class :  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.47040000000000004, 0.36296296296296293, 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = ['sunny', 'cool', 'high', 'weak']\n",
    "demo(Data4,testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
