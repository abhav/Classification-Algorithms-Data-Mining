{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import seed\n",
    "from random import *\n",
    "import time\n",
    "from math import *\n",
    "import math\n",
    "from itertools import groupby\n",
    "from collections import defaultdict\n",
    "import sklearn\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertToLabel(df,pos):\n",
    "    label_encoder = preprocessing.LabelEncoder() \n",
    "    df[pos]= label_encoder.fit_transform(df[pos]) \n",
    "    return df\n",
    "\n",
    "def chunks(df, n):\n",
    "    for i in range(0, len(df), n):\n",
    "        yield df[i:i + n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:569 Y Shape: 31\n"
     ]
    }
   ],
   "source": [
    "X_1 = pd.read_csv(\"project3_dataset1.txt\",header=None, delimiter=\"\\t\")\n",
    "XShape, YShape = X_1.shape\n",
    "print('X Shape:' + str(XShape) + ' Y Shape: '+ str(YShape))\n",
    "Y_1 = X_1[YShape-1]\n",
    "X_1 = X_1.iloc[:, :YShape-1]\n",
    "X_1 = X_1.to_numpy()\n",
    "Y_1 = Y_1.to_numpy()\n",
    "X_1 = sklearn.preprocessing.normalize(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Shape:462 Y Shape: 10\n"
     ]
    }
   ],
   "source": [
    "X_2 = pd.read_csv(\"project3_dataset2.txt\",header=None, delimiter=\"\\t\")\n",
    "XShape, YShape = X_2.shape\n",
    "print('X Shape:' + str(XShape) + ' Y Shape: '+ str(YShape))\n",
    "\n",
    "Y_2 = X_2[YShape-1]\n",
    "X_2 = ConvertToLabel(X_2,4)\n",
    "X_2 = X_2.iloc[:, :YShape-1]\n",
    "X_2 = X_2.to_numpy()\n",
    "Y_2 = Y_2.to_numpy()\n",
    "#X_2 = sklearn.preprocessing.normalize(X_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_1, Y_1, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_2, Y_2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5698924731182796\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataProcessing(X,Y):\n",
    "    data = np.column_stack((X, Y))\n",
    "    np.random.shuffle(data)\n",
    "    RowCount = math.ceil(len(X)/10)\n",
    "    output = list(chunks(data,RowCount))\n",
    "    print('Output Count:'+str(len(output))+' Output X Shape:'+str(len(output[0]))+' Output Y Shape:'+str(len(output[0][0])))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPredictedClass(predicted_labels,test_y):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for i in range(len(predicted_labels)):\n",
    "        if predicted_labels[i] == 1 and test_y[i] == 1:\n",
    "            tp += 1    \n",
    "        if predicted_labels[i] == 0 and test_y[i] == 0:\n",
    "            tn += 1\n",
    "        if predicted_labels[i] == 1 and test_y[i] == 0:\n",
    "            fp += 1\n",
    "        if predicted_labels[i] == 0 and test_y[i] == 1:\n",
    "            fn += 1\n",
    "    try:\n",
    "        accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "    except:\n",
    "        accuracy = 0.0\n",
    "    try:\n",
    "        precision = tp / (tp + fp)\n",
    "    except:\n",
    "        precision = 0.0\n",
    "    try:\n",
    "        recall = tp / (tp + fn)\n",
    "    except:\n",
    "        recall = 0.0\n",
    "    try:\n",
    "        fscore = 2 * (precision * recall)/(precision + recall)\n",
    "    except:\n",
    "        fscore = 0.0\n",
    "    return accuracy,precision,recall,fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateGini(left, right, classes):\n",
    "    n_instances = float(len(left) + len(right))\n",
    "    gini = 0.0\n",
    "    score = 0.0\n",
    "    size = float(len(left))\n",
    "    if size != 0:\n",
    "        for class_val in classes:\n",
    "            tempList = [row[-1] for row in left]\n",
    "            p = tempList.count(class_val) / size\n",
    "            score += p * p\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "\n",
    "    score = 0.0\n",
    "    size = float(len(right))\n",
    "    if size != 0:\n",
    "        for class_val in classes:\n",
    "            tempList = [row[-1] for row in right] \n",
    "            p = tempList.count(class_val) / size\n",
    "            score += p * p\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSplit(dataset, isRandomForest):\n",
    "    classes = list(set([row[-1] for row in dataset]))\n",
    "    indexesList = []\n",
    "\n",
    "    if isRandomForest:\n",
    "        indexesList = [x for x in range(len(dataset[0]) - 1)] \n",
    "        shuffle(indexesList)\n",
    "    else:                                               \n",
    "        indexesList = [x for x in range(len(dataset[0]) - 1)] \n",
    "        \n",
    "    index, value, score, left, right = inf, inf, inf, None, None\n",
    "\n",
    "    for i in indexesList:\n",
    "        for row in dataset:\n",
    "            l, r = [], []\n",
    "            for d in dataset:\n",
    "                if d[i] < row[i]: l.append(d)\n",
    "                else:             r.append(d)\n",
    "            gini = calculateGini(l, r, classes)\n",
    "            if gini <= score:\n",
    "                index, value, score, left, right = i, row[i], gini, l, r\n",
    "    #print(gini)\n",
    "    return {'index': index, 'value': value, 'leftHalf': left, 'rightHalf': right}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    d = defaultdict(float)\n",
    "    for i in outcomes:\n",
    "        d[i] += 1\n",
    "    result = max(d.items(), key=lambda x: x[1])\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodeSplit(node, depth, isRandomForest):\n",
    "    left, right = node['leftHalf'], node['rightHalf']\n",
    "    \n",
    "    del (node['leftHalf'])\n",
    "    del (node['rightHalf'])\n",
    "\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = terminal(left + right)\n",
    "        return\n",
    "\n",
    "    if depth >= maxDepth:\n",
    "        node['left'], node['right'] = terminal(left), terminal(right)\n",
    "        return\n",
    "\n",
    "    if len(left) <= minSize:\n",
    "        node['left'] = terminal(left)\n",
    "    else:\n",
    "        node['left'] = getSplit(left, isRandomForest)\n",
    "        nodeSplit(node['left'], depth + 1, isRandomForest)\n",
    "\n",
    "    if len(right) <= minSize:\n",
    "        node['right'] = terminal(right)\n",
    "    else:\n",
    "        node['right'] = getSplit(right, isRandomForest)\n",
    "        nodeSplit(node['right'], depth + 1, isRandomForest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTree(train, isRandomForest):\n",
    "    root = getSplit(train, isRandomForest)\n",
    "    nodeSplit(root, 1, isRandomForest)\n",
    "    return root\n",
    "\n",
    "def buildDecisionTree(train, test):\n",
    "    tree = buildTree(train, False)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        prediction = predict(tree, row)\n",
    "        predictions.append(prediction)\n",
    "    return (predictions), tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decisionTrees(output):\n",
    "    totalAccuracy, totalPrecision, totalRecall, totalFscore = [],[],[],[]\n",
    "    for i in range(len(output)):\n",
    "        test_x,test_y,train_x = [], [], []\n",
    "        train_x = [row for j,lt in enumerate(output) if j!=i for row in lt]\n",
    "        test_x = output[i]\n",
    "        for arr in test_x:\n",
    "            test_y.append(arr[-1])\n",
    "        predicted_labels, tree = buildDecisionTree(train_x, test_x)\n",
    "        accuracy, precision, recall, fscore = findPredictedClass(predicted_labels,test_y)\n",
    "        print('Round '+ str(i) + ' accuracy:' + str(accuracy))\n",
    "        totalAccuracy.append(accuracy)\n",
    "        totalPrecision.append(precision)\n",
    "        totalRecall.append(recall)\n",
    "        totalFscore.append(fscore)\n",
    "\n",
    "    avgAccuracy  = np.mean(totalAccuracy)\n",
    "    avgPrecision = np.mean(totalPrecision)\n",
    "    avgRecall    = np.mean(totalRecall)\n",
    "    avgFscore    = np.mean(totalFscore)  \n",
    "    print('\\n')\n",
    "    print('Avgerage Accuracy :'+ str(avgAccuracy))\n",
    "    print('Avgerage Precision :'+ str(avgPrecision))\n",
    "    print('Avgerage Recall :'+ str(avgRecall))\n",
    "    print('Avgerage Fscore :'+ str(avgFscore))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDepth = 3\n",
    "minSize = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Count:10 Output X Shape:57 Output Y Shape:31\n",
      "Round 0 accuracy:0.9649122807017544\n",
      "Round 1 accuracy:0.9824561403508771\n",
      "Round 2 accuracy:0.9122807017543859\n",
      "Round 3 accuracy:0.9473684210526315\n",
      "Round 4 accuracy:0.9122807017543859\n",
      "Round 5 accuracy:0.8596491228070176\n",
      "Round 6 accuracy:0.9473684210526315\n",
      "Round 7 accuracy:0.8947368421052632\n",
      "Round 8 accuracy:0.9122807017543859\n",
      "Round 9 accuracy:0.9464285714285714\n",
      "\n",
      "\n",
      "Avgerage Accuracy :0.9279761904761903\n",
      "Avgerage Precision :0.9556895059991033\n",
      "Avgerage Recall :0.8545263476321361\n",
      "Avgerage Fscore :0.9011597359734858\n"
     ]
    }
   ],
   "source": [
    "output = dataProcessing(X_1, Y_1)\n",
    "decisionTrees(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Count:10 Output X Shape:47 Output Y Shape:10\n",
      "Round 0 accuracy:0.8297872340425532\n",
      "Round 1 accuracy:0.6595744680851063\n",
      "Round 2 accuracy:0.6808510638297872\n",
      "Round 3 accuracy:0.8297872340425532\n",
      "Round 4 accuracy:0.7659574468085106\n",
      "Round 5 accuracy:0.723404255319149\n",
      "Round 6 accuracy:0.7021276595744681\n",
      "Round 7 accuracy:0.7446808510638298\n",
      "Round 8 accuracy:0.723404255319149\n",
      "Round 9 accuracy:0.6666666666666666\n",
      "\n",
      "\n",
      "Avgerage Accuracy :0.7326241134751774\n",
      "Avgerage Precision :0.6427467140702434\n",
      "Avgerage Recall :0.5344705075626128\n",
      "Avgerage Fscore :0.5727717588924486\n"
     ]
    }
   ],
   "source": [
    "output = dataProcessing(X_2, Y_2)\n",
    "decisionTrees(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSubSample(dataset):\n",
    "    sample = list()\n",
    "    size = len(dataset)\n",
    "    sampleCount = round(size * samplingRatio)\n",
    "    indexes = [randint(0, size - 1) for x in range(sampleCount)]\n",
    "    for i in indexes:\n",
    "        sample.append(dataset[i])\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baggingPrediction(trees, row):\n",
    "    predictions = [predict(tree, row) for tree in trees]\n",
    "    return max(set(predictions), key=predictions.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildRandomForest(train, test, treesCount):\n",
    "    trees = list()\n",
    "    for i in range(treesCount):\n",
    "        sample = makeSubSample(train)\n",
    "        tree = buildTree(sample, True)\n",
    "        trees.append(tree)\n",
    "    predictions = [baggingPrediction(trees, row) for row in test]\n",
    "    return (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(output):\n",
    "    for j in [1, 5]:\n",
    "        totalAccuracy, totalPrecision, totalRecall, totalFscore = [],[],[],[]\n",
    "        print('Tree Size: ' + str(j))\n",
    "        for i in range(len(output)):\n",
    "            test_x,test_y,train_x = [], [], []\n",
    "            train_x = [row for j,lt in enumerate(output) if j!=i for row in lt]\n",
    "            test_x = output[i]\n",
    "            for arr in test_x:\n",
    "                test_y.append(arr[-1])\n",
    "            predicted_labels = buildRandomForest(train_x, test_x, j)\n",
    "            accuracy, precision, recall, fscore = findPredictedClass(predicted_labels,test_y)\n",
    "            #print('Round '+ str(i) + ' accuracy:' + str(accuracy))\n",
    "            totalAccuracy.append(accuracy)\n",
    "            totalPrecision.append(precision)\n",
    "            totalRecall.append(recall)\n",
    "            totalFscore.append(fscore)\n",
    "\n",
    "        avgAccuracy  = np.mean(totalAccuracy)\n",
    "        avgPrecision = np.mean(totalPrecision)\n",
    "        avgRecall    = np.mean(totalRecall)\n",
    "        avgFscore    = np.mean(totalFscore)  \n",
    "        print('-------------------------------------')\n",
    "        print('Avgerage Accuracy :'+ str(avgAccuracy))\n",
    "        print('Avgerage Precision :'+ str(avgPrecision))\n",
    "        print('Avgerage Recall :'+ str(avgRecall))\n",
    "        print('Avgerage Fscore :'+ str(avgFscore))\n",
    "        print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxDepth = 3\n",
    "minSize = 1\n",
    "samplingRatio = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Count:10 Output X Shape:57 Output Y Shape:31\n",
      "Tree Size: 1\n",
      "-------------------------------------\n",
      "Avgerage Accuracy :0.9227443609022554\n",
      "Avgerage Precision :0.9378499761108458\n",
      "Avgerage Recall :0.856603809054689\n",
      "Avgerage Fscore :0.8889866484323148\n",
      "-------------------------------------\n",
      "Tree Size: 5\n",
      "-------------------------------------\n",
      "Avgerage Accuracy :0.9420112781954886\n",
      "Avgerage Precision :0.9563317384370016\n",
      "Avgerage Recall :0.8882599187988598\n",
      "Avgerage Fscore :0.9181883570715407\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "output = dataProcessing(X_1, Y_1)\n",
    "randomForest(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataSet 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Count:10 Output X Shape:47 Output Y Shape:10\n",
      "Tree Size: 1\n",
      "-------------------------------------\n",
      "Avgerage Accuracy :0.6866884888161484\n",
      "Avgerage Precision :0.5797137503019856\n",
      "Avgerage Recall :0.4437049062049062\n",
      "Avgerage Fscore :0.4661186294729938\n",
      "-------------------------------------\n",
      "Tree Size: 5\n",
      "-------------------------------------\n",
      "Avgerage Accuracy :0.7152209492635024\n",
      "Avgerage Precision :0.6233799533799533\n",
      "Avgerage Recall :0.44980158730158737\n",
      "Avgerage Fscore :0.5111526375649798\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "output = dataProcessing(X_2, Y_2)\n",
    "randomForest(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
